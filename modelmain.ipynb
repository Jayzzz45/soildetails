{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries\n",
    "import os\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "data_df = pd.read_csv('soil_samples_details1.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Extend CSV data to include all orientations\n",
    "expanded_data = []\n",
    "for _, row in data_df.iterrows():\n",
    "    sample_name = row['Sample Name']  \n",
    "    for orientation in range(1, 4):  \n",
    "        img_name = f\"{sample_name}_{orientation}\"  \n",
    "        expanded_data.append([img_name, row['N'], row['P'], row['K']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the expanded data\n",
    "expanded_df = pd.DataFrame(expanded_data, columns=['Sample Name', 'N', 'P', 'K'])\n",
    "expanded_df['filepath'] = expanded_df['Sample Name'] + '.jpg'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "train_df, val_df = train_test_split(expanded_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 validated image filenames.\n",
      "Found 18 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,  # Increased rotation for better generalization\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory='soil images',  # Path to the folder containing images\n",
    "    x_col='filepath',\n",
    "    y_col=['N', 'P', 'K'],\n",
    "    target_size=(224, 224),\n",
    "    class_mode='raw',\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    directory='soil images',  # Path to the folder containing images\n",
    "    x_col='filepath',\n",
    "    y_col=['N', 'P', 'K'],\n",
    "    target_size=(224, 224),\n",
    "    class_mode='raw',\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture using ResNet50 as base\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  \n",
    "output = Dense(3, activation='linear')(x)  # 3 outputs for N, P, K\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers during initial training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\soilmodel\\enve\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - loss: 113929.2344 - mae: 204.1069 - val_loss: 34273.0469 - val_mae: 123.5327\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - loss: 118103.5547 - mae: 193.6089 - val_loss: 27498.5234 - val_mae: 103.6047\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 82624.7266 - mae: 159.1732 - val_loss: 20219.3633 - val_mae: 84.0609\n",
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_soil_content_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"soil_content_model.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\soilmodel\\enve\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"soil_content_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(testimages):\n",
    "    # Load the image\n",
    "    img = cv2.imread(testimages)\n",
    "    \n",
    "    # Resize the image to the same dimensions as training images (224, 224)\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Normalize the image to match the preprocessing used during training\n",
    "    img_normalized = img_resized / 255.0\n",
    "    \n",
    "    # Expand dimensions to add a batch dimension (1, 224, 224, 3)\n",
    "    img_batch = np.expand_dims(img_normalized, axis=0)\n",
    "    \n",
    "    return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_soil_content(testimages):\n",
    "    # Preprocess the image\n",
    "    img_batch = preprocess_image(testimages)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_batch)\n",
    "    \n",
    "    predicted_N, predicted_P, predicted_K = prediction[0]\n",
    "    \n",
    "    return predicted_N, predicted_P, predicted_K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\jayzzz45\\AppData\\Local\\Temp\\ipykernel_47884\\1241951237.py:2: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  test_image_path = \"testimages\\IMG B1_(1).jpg\"  # Replace with your test image path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted Nitrogen (N): 151.45901489257812\n",
      "Predicted Phosphorus (P): 16.67083168029785\n",
      "Predicted Potassium (K): 230.8568878173828\n"
     ]
    }
   ],
   "source": [
    "# Path to the new test image\n",
    "test_image_path = \"testimages\\IMG B1_(1).jpg\"  # Replace with your test image path\n",
    "\n",
    "# Get predictions\n",
    "predicted_N, predicted_P, predicted_K = predict_soil_content(test_image_path)\n",
    "\n",
    "# Display results\n",
    "print(f\"Predicted Nitrogen (N): {predicted_N}\")\n",
    "print(f\"Predicted Phosphorus (P): {predicted_P}\")\n",
    "print(f\"Predicted Potassium (K): {predicted_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
